{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHoSDyYpdh-s"
   },
   "source": [
    "Assignment 7: Neural Networks using Keras and Tensorflow Please see the associated document for questions\n",
    "\n",
    "If you have problems with Keras and Tensorflow on your local installation please make sure they are updated. On Google Colab this notebook runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "02ZYZ-WmdhwH"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BJRCoRmew8Zd",
    "outputId": "8a74f963-06c8-4ba7-fb03-889e43dfa15e"
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters data-loading and formatting\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "(x_train, lbl_train), (x_test, lbl_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-I3g1RrZ0wpI"
   },
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UswCCQLS0s1I"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "y_train = keras.utils.to_categorical(lbl_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(lbl_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "N7Aer42gk1W9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.7787 - accuracy: 0.7827 - val_loss: 0.2583 - val_accuracy: 0.9245\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 0s 550us/step - loss: 0.2402 - accuracy: 0.9295 - val_loss: 0.1849 - val_accuracy: 0.9473\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 0s 548us/step - loss: 0.1796 - accuracy: 0.9478 - val_loss: 0.1509 - val_accuracy: 0.9561\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 0s 550us/step - loss: 0.1430 - accuracy: 0.9591 - val_loss: 0.1355 - val_accuracy: 0.9578\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 0s 549us/step - loss: 0.1239 - accuracy: 0.9631 - val_loss: 0.1277 - val_accuracy: 0.9614\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 0s 550us/step - loss: 0.1046 - accuracy: 0.9696 - val_loss: 0.1108 - val_accuracy: 0.9663\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 0s 554us/step - loss: 0.0947 - accuracy: 0.9723 - val_loss: 0.1055 - val_accuracy: 0.9684\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 0s 545us/step - loss: 0.0826 - accuracy: 0.9767 - val_loss: 0.0984 - val_accuracy: 0.9706\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 0s 543us/step - loss: 0.0734 - accuracy: 0.9787 - val_loss: 0.0969 - val_accuracy: 0.9699\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 0s 554us/step - loss: 0.0668 - accuracy: 0.9801 - val_loss: 0.0959 - val_accuracy: 0.9704\n",
      "Test loss: 0.09586773812770844, Test accuracy 0.9703999757766724\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Define model ##\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "               optimizer=keras.optimizers.SGD(lr = 0.1),\n",
    "        metrics=['accuracy'],)\n",
    "\n",
    "fit_info = model.fit(x_train, y_train,\n",
    "           batch_size=batch_size,\n",
    "           epochs=epochs,\n",
    "           verbose=1,\n",
    "           validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.4300 - accuracy: 0.8664 - val_loss: 0.1058 - val_accuracy: 0.9697\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.1048 - accuracy: 0.9693 - val_loss: 0.0840 - val_accuracy: 0.9733\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0748 - accuracy: 0.9775 - val_loss: 0.0681 - val_accuracy: 0.9784\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0517 - accuracy: 0.9856 - val_loss: 0.0538 - val_accuracy: 0.9819\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0424 - accuracy: 0.9881 - val_loss: 0.0504 - val_accuracy: 0.9836\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0351 - accuracy: 0.9901 - val_loss: 0.0444 - val_accuracy: 0.9851\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0283 - accuracy: 0.9920 - val_loss: 0.0427 - val_accuracy: 0.9847\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0251 - accuracy: 0.9928 - val_loss: 0.0422 - val_accuracy: 0.9860\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0220 - accuracy: 0.9941 - val_loss: 0.0424 - val_accuracy: 0.9857\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0173 - accuracy: 0.9955 - val_loss: 0.0424 - val_accuracy: 0.9869\n",
      "Test loss: 0.04237296059727669, Test accuracy 0.9868999719619751\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.9), metrics=['accuracy'])\n",
    "\n",
    "fit_info = model.fit(x_train, y_train,\n",
    "           batch_size=batch_size,\n",
    "           epochs=epochs,\n",
    "           verbose=1,\n",
    "           validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3\n",
    "### a\n",
    "First we have a convolutional layer, a max pooling layer and flatten it out to find and provide features that we then can examine to get a result. We then have a dense layer and one output layer with 10 nodes that uses the softmax activation function that decides between the 10 nodes.\n",
    "\n",
    "### b\n",
    "Convolutional layers outperform fully connected layers in this case, image classification (explain why)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0I2Bkk_rhUnH"
   },
   "source": [
    "### Question 4) Auto-Encoder for denoising\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4\n",
    "### a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yO0HxKeJ7WFw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def salt_and_pepper(input, noise_level=0.5):\n",
    "    \"\"\"\n",
    "    This applies salt and pepper noise to the input tensor - randomly setting bits to 1 or 0.\n",
    "    Parameters\n",
    "    ----------\n",
    "    input : tensor\n",
    "        The tensor to apply salt and pepper noise to.\n",
    "    noise_level : float\n",
    "        The amount of salt and pepper noise to add.\n",
    "    Returns\n",
    "    -------\n",
    "    tensor\n",
    "        Tensor with salt and pepper noise applied.\n",
    "    \"\"\"\n",
    "    # salt and pepper noise\n",
    "    a = np.random.binomial(size=input.shape, n=1, p=(1 - noise_level))\n",
    "    b = np.random.binomial(size=input.shape, n=1, p=0.5)\n",
    "    c = (a==0) * b\n",
    "    return input * a + c\n",
    "\n",
    "\n",
    "#data preparation\n",
    "flattened_x_train = x_train.reshape(-1,784)\n",
    "flattened_x_train_seasoned = salt_and_pepper(flattened_x_train, noise_level=0.4)\n",
    "\n",
    "flattened_x_test = x_test.reshape(-1,784)\n",
    "flattened_x_test_seasoneed = salt_and_pepper(flattened_x_test, noise_level=0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0GZtZH4ScQeN"
   },
   "outputs": [],
   "source": [
    "\n",
    "latent_dim = 96  \n",
    "\n",
    "input_image = keras.Input(shape=(784,))\n",
    "encoded = Dense(128, activation='relu')(input_image)\n",
    "encoded = Dense(latent_dim, activation='relu')(encoded)\n",
    "decoded = Dense(128, activation='relu')(encoded)\n",
    "decoded = Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = keras.Model(input_image, decoded)\n",
    "encoder_only = keras.Model(input_image, encoded)\n",
    "\n",
    "encoded_input = keras.Input(shape=(latent_dim,))\n",
    "decoder_layer = Sequential(autoencoder.layers[-2:])\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "56iJOKNIKfuB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2434 - val_loss: 0.1507\n",
      "Epoch 2/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1480 - val_loss: 0.1386\n",
      "Epoch 3/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1368 - val_loss: 0.1330\n",
      "Epoch 4/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1314 - val_loss: 0.1293\n",
      "Epoch 5/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1280 - val_loss: 0.1282\n",
      "Epoch 6/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1258 - val_loss: 0.1264\n",
      "Epoch 7/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1239 - val_loss: 0.1248\n",
      "Epoch 8/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1226 - val_loss: 0.1248\n",
      "Epoch 9/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1216 - val_loss: 0.1238\n",
      "Epoch 10/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1207 - val_loss: 0.1236\n",
      "Epoch 11/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1199 - val_loss: 0.1222\n",
      "Epoch 12/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1191 - val_loss: 0.1221\n",
      "Epoch 13/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1187 - val_loss: 0.1222\n",
      "Epoch 14/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1181 - val_loss: 0.1210\n",
      "Epoch 15/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1176 - val_loss: 0.1210\n",
      "Epoch 16/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1170 - val_loss: 0.1209\n",
      "Epoch 17/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1167 - val_loss: 0.1205\n",
      "Epoch 18/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1164 - val_loss: 0.1211\n",
      "Epoch 19/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1165 - val_loss: 0.1205\n",
      "Epoch 20/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1156 - val_loss: 0.1201\n",
      "Epoch 21/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1155 - val_loss: 0.1205\n",
      "Epoch 22/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1154 - val_loss: 0.1204\n",
      "Epoch 23/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1153 - val_loss: 0.1204\n",
      "Epoch 24/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1150 - val_loss: 0.1201\n",
      "Epoch 25/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1148 - val_loss: 0.1207\n",
      "Epoch 26/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1146 - val_loss: 0.1217\n",
      "Epoch 27/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1147 - val_loss: 0.1197\n",
      "Epoch 28/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1143 - val_loss: 0.1200\n",
      "Epoch 29/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1139 - val_loss: 0.1195\n",
      "Epoch 30/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1139 - val_loss: 0.1196\n",
      "Epoch 31/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1139 - val_loss: 0.1195\n",
      "Epoch 32/32\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1137 - val_loss: 0.1197\n"
     ]
    }
   ],
   "source": [
    "fit_info_AE = autoencoder.fit(flattened_x_train_seasoned, flattened_x_train,\n",
    "                epochs=32,\n",
    "                batch_size=64,\n",
    "                shuffle=True,\n",
    "                validation_data=(flattened_x_test_seasoneed, flattened_x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Mr8NGwJ95Sf"
   },
   "outputs": [],
   "source": [
    "num_images = 10\n",
    "np.random.seed(45)\n",
    "random_test_images = np.random.randint(flattened_x_train.shape[0], size=num_images)\n",
    "\n",
    "seasoned_imgs = []\n",
    "seasoned_imgs.append(salt_and_pepper(flattened_x_train, noise_level=0.4))\n",
    "seasoned_imgs.append(salt_and_pepper(flattened_x_train, noise_level=0.5))\n",
    "seasoned_imgs.append(salt_and_pepper(flattened_x_train, noise_level=0.6))\n",
    "seasoned_imgs.append(salt_and_pepper(flattened_x_train, noise_level=0.7))\n",
    "\n",
    "for seasoned in seasoned_imgs:\n",
    "\n",
    "    decoded_imgs = autoencoder.predict(seasoned)\n",
    "    \n",
    "    plt.figure(figsize=(18, 4))\n",
    "\n",
    "    for i, image_idx in enumerate(random_test_images):\n",
    "        ax = plt.subplot(3, num_images, i + 1)\n",
    "        plt.imshow(flattened_x_train[image_idx].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        ax = plt.subplot(3, num_images, num_images + i + 1)\n",
    "        plt.imshow(seasoned[image_idx].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        ax = plt.subplot(3, num_images, 2*num_images + i + 1)\n",
    "        plt.imshow(decoded_imgs[image_idx].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have problem seeing the seasoned picture after 0.4, so in all 3 bottom examples. For the denoising it seems like it starts to get some weird results from 0.6, but very few. At 0.7 however there is a lot of problems and the majority of the pictures are ruined, We would therefore suggest that denoising works at 0.6 but stops working at 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = [0.4, 0.5, 0.6, 0.7]\n",
    "\n",
    "result_season = []\n",
    "result_decoded = []\n",
    "\n",
    "for i in noise:\n",
    "    \n",
    "    seasoned_train = salt_and_pepper(flattened_x_train, noise_level=i) \n",
    "    seasoned_test = salt_and_pepper(flattened_x_test, noise_level=i) \n",
    "    decoded_train = autoencoder.predict(seasoned_train)\n",
    "    decoded_test = autoencoder.predict(seasoned_test)\n",
    "\n",
    "    fit_info = model.fit(seasoned_train.reshape(-1, 28, 28, 1), y_train,\n",
    "           batch_size=batch_size,\n",
    "           epochs=epochs,\n",
    "           verbose=1,\n",
    "           validation_data=(seasoned_test.reshape(-1, 28, 28, 1), y_test))\n",
    "    score = model.evaluate(seasoned_test.reshape(-1, 28, 28, 1), y_test, verbose=0)\n",
    "    result_season.append(score[1])\n",
    "    \n",
    "    fit_info = model.fit(decoded_train.reshape(-1, 28, 28, 1), y_train,\n",
    "           batch_size=batch_size,\n",
    "           epochs=epochs,\n",
    "           verbose=1,\n",
    "           validation_data=(decoded_test.reshape(-1, 28, 28, 1), y_test))\n",
    "    score = model.evaluate(decoded_test.reshape(-1, 28, 28, 1), y_test, verbose=0)\n",
    "    result_decoded.append(score[1])\n",
    "    \n",
    "\n",
    "plt.plot(noise, result_season, label = \"Seasoned\")\n",
    "plt.plot(noise, result_decoded, label = \"Decoded\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decoded version is better all the way until 0.7 where seasoned is better. However that was the point where the decoder stopped working, so it is in fact better as long as it works."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment_7_NN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
