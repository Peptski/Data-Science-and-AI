{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-sTsDfIVKsmL"
   },
   "source": [
    "# DAT405 Introduction to Data Science and AI \n",
    "## Assignment 4: Spam classification using Naïve Bayes \n",
    "\n",
    "The exercise takes place in a notebook environment where you can chose to use Jupyter or Google Colabs. We recommend you use Google Colabs as it will facilitate remote group-work and makes the assignment less technical. \n",
    "Hints:\n",
    "You can execute certain linux shell commands by prefixing the command with `!`. You can insert Markdown cells and code cells. The first you can use for documenting and explaining your results the second you can use writing code snippets that execute the tasks required.  \n",
    "\n",
    "In this assignment you will implement a Naïve Bayes classifier in Python that will classify emails into spam and non-spam (“ham”) classes.  Your program should be able to train on a given set of spam and “ham” datasets. \n",
    "You will work with the datasets available at https://spamassassin.apache.org/old/publiccorpus/. There are three types of files in this location: \n",
    "-\teasy-ham: non-spam messages typically quite easy to differentiate from spam messages. \n",
    "-\thard-ham: non-spam messages more difficult to differentiate \n",
    "-\tspam: spam messages \n",
    "\n",
    "**Execute the cell below to download and extract the data into the environment of the notebook -- it will take a few seconds.** If you chose to use Jupyter notebooks you will have to run the commands in the cell below on your local computer, with Windows you can use 7zip (https://www.7-zip.org/download.html) to decompress the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Wa37fBwRF-xe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2021-02-15 16:35:40--  https://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2\n",
      "Resolving spamassassin.apache.org (spamassassin.apache.org)... 207.244.88.140, 95.216.26.30\n",
      "Connecting to spamassassin.apache.org (spamassassin.apache.org)|207.244.88.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1677144 (1,6M) [application/x-bzip2]\n",
      "Saving to: '20021010_easy_ham.tar.bz2'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  3%  279K 6s\n",
      "    50K .......... .......... .......... .......... ..........  6% 15,1M 3s\n",
      "   100K .......... .......... .......... .......... ..........  9%  554K 3s\n",
      "   150K .......... .......... .......... .......... .......... 12% 14,8M 2s\n",
      "   200K .......... .......... .......... .......... .......... 15%  584K 2s\n",
      "   250K .......... .......... .......... .......... .......... 18% 16,1M 2s\n",
      "   300K .......... .......... .......... .......... .......... 21% 13,3M 1s\n",
      "   350K .......... .......... .......... .......... .......... 24%  588K 1s\n",
      "   400K .......... .......... .......... .......... .......... 27% 14,7M 1s\n",
      "   450K .......... .......... .......... .......... .......... 30% 18,9M 1s\n",
      "   500K .......... .......... .......... .......... .......... 33% 15,8M 1s\n",
      "   550K .......... .......... .......... .......... .......... 36% 18,3M 1s\n",
      "   600K .......... .......... .......... .......... .......... 39% 16,9M 1s\n",
      "   650K .......... .......... .......... .......... .......... 42% 21,3M 1s\n",
      "   700K .......... .......... .......... .......... .......... 45%  723K 1s\n",
      "   750K .......... .......... .......... .......... .......... 48% 7,05M 1s\n",
      "   800K .......... .......... .......... .......... .......... 51% 14,7M 1s\n",
      "   850K .......... .......... .......... .......... .......... 54% 17,2M 0s\n",
      "   900K .......... .......... .......... .......... .......... 58% 19,8M 0s\n",
      "   950K .......... .......... .......... .......... .......... 61% 19,9M 0s\n",
      "  1000K .......... .......... .......... .......... .......... 64% 21,6M 0s\n",
      "  1050K .......... .......... .......... .......... .......... 67% 22,3M 0s\n",
      "  1100K .......... .......... .......... .......... .......... 70% 26,1M 0s\n",
      "  1150K .......... .......... .......... .......... .......... 73% 25,8M 0s\n",
      "  1200K .......... .......... .......... .......... .......... 76% 20,7M 0s\n",
      "  1250K .......... .......... .......... .......... .......... 79% 24,4M 0s\n",
      "  1300K .......... .......... .......... .......... .......... 82% 26,3M 0s\n",
      "  1350K .......... .......... .......... .......... .......... 85% 27,7M 0s\n",
      "  1400K .......... .......... .......... .......... .......... 88% 22,5M 0s\n",
      "  1450K .......... .......... .......... .......... .......... 91% 23,0M 0s\n",
      "  1500K .......... .......... .......... .......... .......... 94%  865K 0s\n",
      "  1550K .......... .......... .......... .......... .......... 97% 16,7M 0s\n",
      "  1600K .......... .......... .......... .......              100% 14,9M=0,6s\n",
      "\n",
      "2021-02-15 16:35:41 (2,49 MB/s) - '20021010_easy_ham.tar.bz2' saved [1677144/1677144]\n",
      "\n",
      "--2021-02-15 16:35:41--  https://spamassassin.apache.org/old/publiccorpus/20021010_hard_ham.tar.bz2\n",
      "Resolving spamassassin.apache.org (spamassassin.apache.org)... 207.244.88.140, 95.216.26.30\n",
      "Connecting to spamassassin.apache.org (spamassassin.apache.org)|207.244.88.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1021126 (997K) [application/x-bzip2]\n",
      "Saving to: '20021010_hard_ham.tar.bz2'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  5%  274K 3s\n",
      "    50K .......... .......... .......... .......... .......... 10%  539K 2s\n",
      "   100K .......... .......... .......... .......... .......... 15% 7,91M 2s\n",
      "   150K .......... .......... .......... .......... .......... 20% 19,8M 1s\n",
      "   200K .......... .......... .......... .......... .......... 25%  577K 1s\n",
      "   250K .......... .......... .......... .......... .......... 30% 11,1M 1s\n",
      "   300K .......... .......... .......... .......... .......... 35%  581K 1s\n",
      "   350K .......... .......... .......... .......... .......... 40% 13,0M 1s\n",
      "   400K .......... .......... .......... .......... .......... 45% 11,8M 1s\n",
      "   450K .......... .......... .......... .......... .......... 50% 17,5M 0s\n",
      "   500K .......... .......... .......... .......... .......... 55% 17,2M 0s\n",
      "   550K .......... .......... .......... .......... .......... 60%  618K 0s\n",
      "   600K .......... .......... .......... .......... .......... 65% 9,86M 0s\n",
      "   650K .......... .......... .......... .......... .......... 70% 15,4M 0s\n",
      "   700K .......... .......... .......... .......... .......... 75% 15,6M 0s\n",
      "   750K .......... .......... .......... .......... .......... 80% 16,3M 0s\n",
      "   800K .......... .......... .......... .......... .......... 85% 14,5M 0s\n",
      "   850K .......... .......... .......... .......... .......... 90% 18,4M 0s\n",
      "   900K .......... .......... .......... .......... .......... 95% 17,2M 0s\n",
      "   950K .......... .......... .......... .......... .......   100% 17,4M=0,6s\n",
      "\n",
      "2021-02-15 16:35:42 (1,68 MB/s) - '20021010_hard_ham.tar.bz2' saved [1021126/1021126]\n",
      "\n",
      "--2021-02-15 16:35:42--  https://spamassassin.apache.org/old/publiccorpus/20021010_spam.tar.bz2\n",
      "Resolving spamassassin.apache.org (spamassassin.apache.org)... 207.244.88.140, 95.216.26.30\n",
      "Connecting to spamassassin.apache.org (spamassassin.apache.org)|207.244.88.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1192582 (1,1M) [application/x-bzip2]\n",
      "Saving to: '20021010_spam.tar.bz2'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  4%  273K 4s\n",
      "    50K .......... .......... .......... .......... ..........  8%  551K 3s\n",
      "   100K .......... .......... .......... .......... .......... 12% 12,2M 2s\n",
      "   150K .......... .......... .......... .......... .......... 17% 13,9M 1s\n",
      "   200K .......... .......... .......... .......... .......... 21%  570K 1s\n",
      "   250K .......... .......... .......... .......... .......... 25% 16,7M 1s\n",
      "   300K .......... .......... .......... .......... .......... 30%  573K 1s\n",
      "   350K .......... .......... .......... .......... .......... 34% 13,7M 1s\n",
      "   400K .......... .......... .......... .......... .......... 38% 11,4M 1s\n",
      "   450K .......... .......... .......... .......... .......... 42%  580K 1s\n",
      "   500K .......... .......... .......... .......... .......... 47% 15,9M 1s\n",
      "   550K .......... .......... .......... .......... .......... 51% 16,5M 1s\n",
      "   600K .......... .......... .......... .......... .......... 55% 15,0M 0s\n",
      "   650K .......... .......... .......... .......... .......... 60% 22,4M 0s\n",
      "   700K .......... .......... .......... .......... .......... 64%  623K 0s\n",
      "   750K .......... .......... .......... .......... .......... 68% 13,8M 0s\n",
      "   800K .......... .......... .......... .......... .......... 72% 13,1M 0s\n",
      "   850K .......... .......... .......... .......... .......... 77% 16,8M 0s\n",
      "   900K .......... .......... .......... .......... .......... 81% 14,0M 0s\n",
      "   950K .......... .......... .......... .......... .......... 85% 15,9M 0s\n",
      "  1000K .......... .......... .......... .......... .......... 90% 13,8M 0s\n",
      "  1050K .......... .......... .......... .......... .......... 94% 16,5M 0s\n",
      "  1100K .......... .......... .......... .......... .......... 98% 22,0M 0s\n",
      "  1150K .......... ....                                       100% 17,2M=0,7s\n",
      "\n",
      "2021-02-15 16:35:43 (1,69 MB/s) - '20021010_spam.tar.bz2' saved [1192582/1192582]\n",
      "\n",
      "tar: Error opening archive: Can't initialize filter; unable to run program \"bzip2 -d\"\n",
      "tar: Error opening archive: Can't initialize filter; unable to run program \"bzip2 -d\"\n",
      "tar: Error opening archive: Can't initialize filter; unable to run program \"bzip2 -d\"\n"
     ]
    }
   ],
   "source": [
    "#Download and extract data\n",
    "!wget https://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2\n",
    "!wget https://spamassassin.apache.org/old/publiccorpus/20021010_hard_ham.tar.bz2\n",
    "!wget https://spamassassin.apache.org/old/publiccorpus/20021010_spam.tar.bz2\n",
    "!tar -xjf 20021010_easy_ham.tar.bz2\n",
    "!tar -xjf 20021010_hard_ham.tar.bz2\n",
    "!tar -xjf 20021010_spam.tar.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdH1XTepLjZ3"
   },
   "source": [
    "*The* data is now in the three folders `easy_ham`, `hard_ham`, and `spam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "A53Gw00fBLG2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls -lah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGlWPVnSNzT7"
   },
   "source": [
    "###1. Preprocessing: \n",
    "1.\tNote that the email files contain a lot of extra information, besides the actual message. Ignore that and run on the entire text. \n",
    "2.\tWe don’t want to train and test on the same data. Split the spam and the ham datasets in a training set and a test set. (`hamtrain`, `spamtrain`, `hamtest`, and `spamtest`) **0.5p**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "J2sllUWXKblD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['From sentto-2242572-56028-1034088521-zzzz=example.com@returns.groups.yahoo.com  Tue Oct  8 17:02:19 2002\\n', 'Return-Path: <sentto-2242572-56028-1034088521-zzzz=example.com@returns.groups.yahoo.com>\\n', 'Delivered-To: zzzz@localhost.example.com\\n', 'Received: from localhost (jalapeno [127.0.0.1])\\n', '\\tby example.com (Postfix) with ESMTP id DC7B516F17\\n', '\\tfor <zzzz@localhost>; Tue,  8 Oct 2002 17:01:48 +0100 (IST)\\n', 'Received: from jalapeno [127.0.0.1]\\n', '\\tby localhost with IMAP (fetchmail-5.9.0)\\n', '\\tfor zzzz@localhost (single-drop); Tue, 08 Oct 2002 17:01:48 +0100 (IST)\\n', 'Received: from n13.grp.scd.yahoo.com (n13.grp.scd.yahoo.com\\n', '    [66.218.66.68]) by dogma.slashnull.org (8.11.6/8.11.6) with SMTP id\\n', '    g98EuBK20554 for <zzzz@example.com>; Tue, 8 Oct 2002 15:56:14 +0100\\n', 'X-Egroups-Return: sentto-2242572-56028-1034088521-zzzz=example.com@returns.groups.yahoo.com\\n', 'Received: from [66.218.67.193] by n13.grp.scd.yahoo.com with NNFMP;\\n', '    08 Oct 2002 14:48:41 -0000\\n', 'X-Sender: skitster@hotmail.com\\n', 'X-Apparently-To: zzzzteana@yahoogroups.com\\n', 'Received: (EGP: mail-8_2_2_0); 8 Oct 2002 14:48:41 -0000\\n', 'Received: (qmail 60589 invoked from network); 8 Oct 2002 14:48:40 -0000\\n', 'Received: from unknown (66.218.66.217) by m11.grp.scd.yahoo.com with QMQP;\\n', '    8 Oct 2002 14:48:40 -0000\\n', 'Received: from unknown (HELO hotmail.com) (64.4.17.7) by\\n', '    mta2.grp.scd.yahoo.com with SMTP; 8 Oct 2002 14:48:40 -0000\\n', 'Received: from mail pickup service by hotmail.com with Microsoft SMTPSVC;\\n', '    Tue, 8 Oct 2002 07:48:40 -0700\\n', 'Received: from 217.34.194.18 by lw11fd.law11.hotmail.msn.com with HTTP;\\n', '    Tue, 08 Oct 2002 14:48:40 GMT\\n', 'To: zzzzteana@yahoogroups.com\\n', 'Message-Id: <F7KqwUj9sEFSqEP5kuG0000347c@hotmail.com>\\n', 'X-Originalarrivaltime: 08 Oct 2002 14:48:40.0859 (UTC) FILETIME=[CAC3E6B0:01C26ED9]\\n', 'From: \"Scott Wood\" <skitster@hotmail.com>\\n', 'X-Originating-Ip: [217.34.194.18]\\n', 'X-Yahoo-Profile: fromage_frenzy\\n', 'MIME-Version: 1.0\\n', 'Mailing-List: list zzzzteana@yahoogroups.com; contact\\n', '    forteana-owner@yahoogroups.com\\n', 'Delivered-To: mailing list zzzzteana@yahoogroups.com\\n', 'Precedence: bulk\\n', 'List-Unsubscribe: <mailto:zzzzteana-unsubscribe@yahoogroups.com>\\n', 'Date: Tue, 08 Oct 2002 15:48:40 +0100\\n', 'Subject: [zzzzteana] Punch bags filled with incontinence pads\\n', 'Reply-To: zzzzteana@yahoogroups.com\\n', 'Content-Type: text/plain; charset=US-ASCII\\n', 'Content-Transfer-Encoding: 7bit\\n', 'X-Spam-Status: No, hits=-3.3 required=5.0\\n', '\\ttests=AWL,FROM_EGROUPS,GROUPS_YAHOO_1,HOTMAIL_FOOTER5,\\n', '\\t      T_NONSENSE_FROM_10_20\\n', '\\tversion=2.50-cvs\\n', 'X-Spam-Level: \\n', '\\n', '\\n', '\\n', 'http://www.thisislocallondon.co.uk/news/weird/display.var.633932.Bizarre+London.0.html\\n', '\\n', 'An investigation has been launched after punch bags on sale in Greenwich \\n', 'were found to be stuffed with incontinence pads and bandages.\\n', '\\n', 'Trading standards officers, working for Greenwich Council, were alerted to \\n', 'the situation after a Bryan punch bag, purchased in Argos, in Charlton Road, \\n', 'Charlton, was found to be full of bandages.\\n', '\\n', 'Also stuffed inside the piece of sporting equipment was a letter from a \\n', \"woman in Fife stating how she felt quite disgusted' about the bag and asking \\n\", 'for the filling to be tested.\\n', '\\n', 'The unfortunate shopper had bought his first bag, at Argos, in Lewisham High \\n', 'Street, but had returned it because on investigation of a leak he was \\n', 'horrified to discover it was filled with incontinence pads.\\n', '\\n', 'So far, officers have purchased two of the punch bags, only to find they \\n', 'contain incontinence pads and strips of shredded duvet.\\n', '\\n', 'Cabinet member for public services Councillor Angela Cornforth said: \"This \\n', 'is one of the strangest stories I have every heard.\\n', '\\n', '\"Our officers are in the process of investigating and will no doubt discover \\n', 'why the bags contain such unusual contents.\"\\n', '\\n', '12:18 Tuesday 8th October 2002\\n', '\\n', '\\n', '\\n', '\\n', '_________________________________________________________________\\n', 'Chat with friends online, try MSN Messenger: http://messenger.msn.com\\n', '\\n', '\\n', '------------------------ Yahoo! Groups Sponsor ---------------------~-->\\n', 'Plan to Sell a Home?\\n', 'http://us.click.yahoo.com/J2SnNA/y.lEAA/MVfIAA/7gSolB/TM\\n', '---------------------------------------------------------------------~->\\n', '\\n', 'To unsubscribe from this group, send an email to:\\n', 'forteana-unsubscribe@egroups.com\\n', '\\n', ' \\n', '\\n', 'Your use of Yahoo! Groups is subject to http://docs.yahoo.com/info/terms/ \\n', '\\n', '\\n', '\\n']\n"
     ]
    }
   ],
   "source": [
    "#pre-processing code here\n",
    "\n",
    "my_file = open(\"data/easy_ham/0350.dabd503455d16db68a0e4bad24ffc736\", \"r\")\n",
    "content_list = my_file. readlines()\n",
    "print(content_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnbrbI0_OKCF"
   },
   "source": [
    "###2. Write a Python program that: \n",
    "1.\tUses four datasets (`hamtrain`, `spamtrain`, `hamtest`, and `spamtest`) \n",
    "2.\tTrains a Naïve Bayes classifier (e.g. Sklearn) on `hamtrain` and `spamtrain`, that classifies the test sets and reports True Positive and False Negative rates on the `hamtest` and `spamtest` datasets. You can use `CountVectorizer` to transform the email texts into vectors. Please note that there are different types of Naïve Bayes Classifier in SKlearn ([Documentation here](https://scikit-learn.org/stable/modules/naive_bayes.html)). Test two of these classifiers that are well suited for this problem\n",
    "    - Multinomial Naive Bayes  \n",
    "    - Bernoulli Naive Bayes. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MJERHSCcGNaW"
   },
   "outputs": [],
   "source": [
    "#Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Explain how the classifiers differ. What different interpretations do they have? **1p** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nI1bPDCvQxen"
   },
   "source": [
    "Your discussion here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDFS3uFFUcS7"
   },
   "source": [
    "### 3.Run your program on \n",
    "-\tSpam versus easy-ham \n",
    "-\tSpam versus (hard-ham + easy-ham). \n",
    "-   Discuss your results **2.5p** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gool_zb8Qzzy"
   },
   "outputs": [],
   "source": [
    "#Code to report results here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkfQWBB4UhYd"
   },
   "source": [
    "# 4.\tTo avoid classification based on common and uninformative words it is common to filter these out. \n",
    "\n",
    "**a.** Argue why this may be useful. Try finding the words that are too common/uncommon in the dataset. **1p** \n",
    "\n",
    "**b.** Use the parameters in Sklearn’s `CountVectorizer` to filter out these words. Update the program from point 3 and run it on your data and report and discuss your results. You have two options to do this in Sklearn: either using the words found in part (a) or letting Sklearn do it for you. Argue for your decision-making. **1p** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qt7ELzEqUfas"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcyVfOZFU4F_"
   },
   "source": [
    "### 5. Eeking out further performance\n",
    "**a.**  Use a lemmatizer to normalize the text (for example from the `nltk` library). For one implementation look at the documentation ([here](https://scikit-learn.org/stable/modules/feature_extraction.html#customizing-the-vectorizer-classes)). Run your program again and answer the following questions: \n",
    "  - Why can lemmatization help?\n",
    "  -\tDoes the result improve from 3 and 4? Discuss. **1.5p** \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.** The split of the data set into a training set and a test set can lead to very skewed results. Why is this, and do you have suggestions on remedies? \n",
    " What do you expect would happen if your training set were mostly spam messages while your test set were mostly ham messages?  **1p** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_nyGug9U4f3"
   },
   "source": [
    "**c.** Re-estimate your classifier using `fit_prior` parameter set to `false`, and answer the following questions:\n",
    "  - What does this parameter mean?\n",
    "  - How does this alter the predictions? Discuss why or why not. **0.5p** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d.** The python model includes smoothing (`alpha` parameter ), explain why this can be important. \n",
    "  - What would happen if in the training data set the word 'money' only appears in spam examples? What would the model predict about a message containing the word 'money'? Does the prediction depend on the rest of the message and is that reasonable? Explain your reasoning  **1p** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ND6FKoexVAhW"
   },
   "source": [
    "### What to report and how to hand in.\n",
    "\n",
    "- You will need to clearly report all results in the notebook in a clear and appropriate way, either using plots or code output (f.x. \"print statements\"). \n",
    "- The notebook must be reproducible, that means, we must be able to use the `Run all` function from the `Runtime` menu and reproduce all your results. **Please check this before handing in.** \n",
    "- Save the notebook and share a link to the notebook (Press share in upper left corner, and use `Get link` option. **Please make sure to allow all with the link to open and edit.**\n",
    "- Edits made after submission deadline will be ignored, graders will recover the last saved version before deadline from the revisions history.\n",
    "- **Please make sure all cells are executed and all the output is clearly readable/visible to anybody opening the notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8bI3z_spVacz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}